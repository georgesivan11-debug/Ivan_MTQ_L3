import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import os
from sklearn.metrics import (
    confusion_matrix, roc_curve, auc,
    classification_report, f1_score,
    roc_auc_score, precision_score, recall_score
)
import warnings
warnings.filterwarnings('ignore')

# ============================================================
# CONFIGURATION
# ============================================================
st.set_page_config(
    page_title="DÃ©tection de Fraude ğŸ”",
    page_icon="ğŸ”",
    layout="wide"
)
st.title("ğŸ” DÃ©tection de Fraude par Carte de CrÃ©dit")
st.markdown("---")

# ============================================================
# CHARGEMENT DU MODÃˆLE ET DES DONNÃ‰ES
# ============================================================
@st.cache_resource
def load_model():
    try:
        if not os.path.exists('creditcard.pkl'):
            return None, None, None, []
        with open('creditcard.pkl', 'rb') as f:
            bundle = pickle.load(f)
        if isinstance(bundle, dict):
            return (bundle['model'], bundle['scaler_amount'],
                    bundle['scaler_time'], bundle['feature_cols'])
        else:
            return bundle, None, None, []
    except Exception as e:
        st.error(f"Erreur chargement modÃ¨le : {e}")
        return None, None, None, []

@st.cache_data
def load_data():
    for path in ['creditcard.csv', 'CreditCard.csv', 'CREDITCARD.csv']:
        if os.path.exists(path):
            try:
                return pd.read_csv(path)
            except Exception:
                continue
    return None

model, scaler_amount, scaler_time, feature_cols = load_model()
df = load_data()

# ============================================================
# SIDEBAR â€” NAVIGATION
# ============================================================
st.sidebar.title("Navigation")
page = st.sidebar.radio(
    "Choisissez une page :",
    ["ğŸ  Accueil", "ğŸ”® PrÃ©diction", "ğŸ“Š Analyse des donnÃ©es",
     "ğŸ“ˆ Performances du modÃ¨le", "ğŸ“‚ PrÃ©diction par fichier", "â„¹ï¸ Ã€ propos"]
)

# ============================================================
# PAGE â€” ACCUEIL
# ============================================================
if page == "ğŸ  Accueil":
    st.header("Bienvenue sur l'application de DÃ©tection de Fraude !")

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ“– Ã€ propos du projet")
        st.write("""
        Cette application utilise le **Machine Learning** pour dÃ©tecter
        les transactions frauduleuses par carte de crÃ©dit.

        Le problÃ¨me est une **classification binaire** :
        - **Classe 0** : Transaction lÃ©gitime
        - **Classe 1** : Transaction frauduleuse

        Le principal dÃ©fi : **fort dÃ©sÃ©quilibre de classes**
        (moins de 6% de fraudes dans les donnÃ©es rÃ©elles).
        """)
    with col2:
        st.subheader("ğŸ¯ FonctionnalitÃ©s")
        st.write("""
        - âœ… PrÃ©diction individuelle en temps rÃ©el
        - ğŸ“Š Exploration interactive des donnÃ©es
        - ğŸ“ˆ MÃ©triques complÃ¨tes (F1, AUC-ROC, Rappel)
        - ğŸ“‚ PrÃ©diction sur **n'importe quel fichier CSV**
        - ğŸ¤– ModÃ¨le Random Forest optimisÃ© par GridSearchCV
        """)

    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1:
        if model is not None:
            st.success("âœ… ModÃ¨le chargÃ© avec succÃ¨s !")
        else:
            st.warning("âš ï¸ ModÃ¨le non disponible.")
    with col2:
        if df is not None:
            st.success(f"âœ… Dataset : {len(df):,} transactions")
        else:
            st.error("âŒ Dataset non disponible")
    with col3:
        if df is not None and 'Class' in df.columns:
            n = df['Class'].sum()
            st.info(f"âš ï¸ Fraudes : {n} ({n/len(df)*100:.2f}%)")

    st.info("ğŸ‘ˆ Utilisez le menu Ã  gauche pour naviguer entre les pages")

# ============================================================
# PAGE â€” PRÃ‰DICTION INDIVIDUELLE
# ============================================================
elif page == "ğŸ”® PrÃ©diction":
    st.header("PrÃ©diction sur une Transaction")

    if model is None:
        st.error("âŒ ModÃ¨le non disponible. VÃ©rifiez que creditcard.pkl est bien prÃ©sent.")
        st.stop()

    if not feature_cols:
        st.error("âŒ Impossible de lire les colonnes depuis creditcard.pkl.")
        st.stop()

    st.write("Entrez les caractÃ©ristiques d'une transaction pour obtenir une prÃ©diction :")

    col_left, col_right = st.columns(2)

    with col_left:
        st.subheader("ğŸ’³ ParamÃ¨tres de la transaction")

        amount  = st.number_input("ğŸ’° Montant (â‚¬)", min_value=0.0,
                                   max_value=25000.0, value=150.0, step=10.0)
        time_v  = st.number_input("â±ï¸ Temps (secondes)", min_value=0.0,
                                   value=50000.0, step=1000.0)

        v_features = [c for c in feature_cols if c.startswith('V')]
        st.markdown("**Variables PCA :**")
        grid = st.columns(2)
        v_vals = {}
        for i, feat in enumerate(v_features):
            with grid[i % 2]:
                v_vals[feat] = st.number_input(
                    feat, value=0.0, step=0.1,
                    key=f"pred_{feat}", format="%.3f"
                )

        st.markdown("---")
        if df is not None and 'Class' in df.columns:
            use_ex = st.toggle("ğŸ² Charger un exemple alÃ©atoire du dataset")
            if use_ex:
                ex_type = st.radio("Type :", ["Normale", "Fraude"], horizontal=True)
                classe  = 0 if ex_type == "Normale" else 1
                row = df[df['Class'] == classe].sample(
                    1, random_state=np.random.randint(0, 999)
                )
                if 'Amount' in row.columns:
                    amount = float(row['Amount'].values[0])
                if 'Time' in row.columns:
                    time_v = float(row['Time'].values[0])
                for feat in v_features:
                    if feat in row.columns:
                        v_vals[feat] = float(row[feat].values[0])
                st.success(f"Exemple Â« {ex_type} Â» chargÃ© !")

    with col_right:
        st.subheader("ğŸ¯ RÃ©sultat de la prÃ©diction")

        if st.button("ğŸ”® Analyser cette transaction",
                     type="primary", use_container_width=True):
            try:
                # Construction du vecteur dans le bon ordre
                input_row = {}
                for col in feature_cols:
                    if col == 'Amount':
                        input_row[col] = amount
                    elif col == 'Time':
                        input_row[col] = time_v
                    else:
                        input_row[col] = v_vals.get(col, 0.0)

                X_in = pd.DataFrame([input_row])[feature_cols]

                # Normalisation avec les scalers sauvegardÃ©s
                if scaler_amount is not None and 'Amount' in X_in.columns:
                    X_in['Amount'] = scaler_amount.transform(X_in[['Amount']])
                if scaler_time is not None and 'Time' in X_in.columns:
                    X_in['Time'] = scaler_time.transform(X_in[['Time']])

                prediction = model.predict(X_in)[0]
                proba      = model.predict_proba(X_in)[0]

                # RÃ©sultat
                if prediction == 1:
                    st.error("ğŸš¨ TRANSACTION FRAUDULEUSE DÃ‰TECTÃ‰E !")
                else:
                    st.success("âœ… TRANSACTION LÃ‰GITIME")

                st.markdown("---")
                c1, c2 = st.columns(2)
                c1.metric("ProbabilitÃ© Normale", f"{proba[0]*100:.1f}%")
                c2.metric("ProbabilitÃ© Fraude",  f"{proba[1]*100:.1f}%")

                # Graphique probabilitÃ©s
                fig, ax = plt.subplots(figsize=(7, 3))
                ax.barh(['Normale', 'Fraude'], proba,
                        color=['#2ecc71', '#e74c3c'])
                ax.set_xlim(0, 1)
                ax.set_xlabel('ProbabilitÃ©')
                ax.set_title('ProbabilitÃ©s par classe', fontweight='bold')
                for i, v in enumerate(proba):
                    ax.text(v + 0.01, i, f'{v:.2%}',
                            va='center', fontweight='bold')
                ax.grid(axis='x', alpha=0.3)
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

                st.markdown("---")
                st.markdown(f"**Montant :** {amount:.2f} â‚¬")
                st.markdown(f"**DÃ©cision :** {'ğŸ”´ FRAUDE' if prediction==1 else 'ğŸŸ¢ NORMALE'}")
                st.markdown(f"**Confiance :** {max(proba)*100:.1f}%")

            except Exception as e:
                st.error(f"âŒ Erreur lors de la prÃ©diction : {e}")

# ============================================================
# PAGE â€” ANALYSE DES DONNÃ‰ES
# ============================================================
elif page == "ğŸ“Š Analyse des donnÃ©es":
    st.header("Exploration et Visualisation des DonnÃ©es")

    if df is None:
        st.error("âŒ Dataset non disponible.")
        st.stop()

    # KPIs
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Total transactions", f"{len(df):,}")
    if 'Class' in df.columns:
        col2.metric("Fraudes",      f"{df['Class'].sum()}")
        col3.metric("Taux fraude",  f"{df['Class'].mean()*100:.2f}%")
    col4.metric("Variables",        f"{df.shape[1]}")

    st.markdown("---")

    if 'Class' in df.columns:
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("RÃ©partition des classes")
            counts = df['Class'].value_counts()
            fig, ax = plt.subplots(figsize=(6, 4))
            bars = ax.bar(['Normale (0)', 'Fraude (1)'], counts.values,
                          color=['#2ecc71', '#e74c3c'], edgecolor='black')
            for bar, val in zip(bars, counts.values):
                ax.text(bar.get_x() + bar.get_width()/2,
                        bar.get_height() + 10,
                        f'{val:,}\n({val/len(df)*100:.2f}%)',
                        ha='center', fontweight='bold')
            ax.set_ylabel("Nombre")
            ax.set_ylim(0, counts.max() * 1.25)
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col2:
            if 'Amount' in df.columns:
                st.subheader("Distribution des montants")
                fig, ax = plt.subplots(figsize=(6, 4))
                df[df['Class']==0]['Amount'].clip(upper=500).hist(
                    bins=50, ax=ax, color='#2ecc71',
                    alpha=0.7, label='Normale', density=True)
                df[df['Class']==1]['Amount'].clip(upper=500).hist(
                    bins=30, ax=ax, color='#e74c3c',
                    alpha=0.7, label='Fraude', density=True)
                ax.set_xlabel("Montant (â‚¬)")
                ax.legend()
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

    # Matrice de corrÃ©lation
    st.subheader("ğŸ”— Matrice de corrÃ©lation")
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if len(num_cols) > 1:
        fig, ax = plt.subplots(figsize=(12, 8))
        mask = np.triu(np.ones_like(df[num_cols].corr(), dtype=bool))
        sns.heatmap(df[num_cols].corr(), mask=mask, cmap='RdBu_r',
                    center=0, ax=ax, linewidths=0.3,
                    cbar_kws={'label': 'CorrÃ©lation'})
        ax.set_title("Matrice de corrÃ©lation", fontweight='bold')
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

    with st.expander("ğŸ“‹ Voir les donnÃ©es brutes"):
        st.dataframe(df.head(100), use_container_width=True)

# ============================================================
# PAGE â€” PERFORMANCES
# ============================================================
elif page == "ğŸ“ˆ Performances du modÃ¨le":
    st.header("Ã‰valuation des Performances du ModÃ¨le")

    if model is None or df is None:
        st.error("âŒ ModÃ¨le ou donnÃ©es non disponibles.")
        st.stop()

    if 'Class' not in df.columns:
        st.warning("âš ï¸ Le dataset ne contient pas de colonne 'Class'.")
        st.stop()

    try:
        from sklearn.model_selection import train_test_split
        X = df.drop('Class', axis=1).copy()
        y = df['Class']

        if scaler_amount is not None and 'Amount' in X.columns:
            X['Amount'] = scaler_amount.transform(X[['Amount']])
        if scaler_time is not None and 'Time' in X.columns:
            X['Time'] = scaler_time.transform(X[['Time']])

        cols = [c for c in feature_cols if c in X.columns] if feature_cols else X.columns.tolist()
        X = X[cols]

        _, X_test, _, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        y_pred  = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1]

        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric("Accuracy",  f"{model.score(X_test, y_test):.4f}")
        col2.metric("F1-Score",  f"{f1_score(y_test, y_pred):.4f}")
        col3.metric("AUC-ROC",   f"{roc_auc_score(y_test, y_proba):.4f}")
        col4.metric("PrÃ©cision", f"{precision_score(y_test, y_pred, zero_division=0):.4f}")
        col5.metric("Rappel",    f"{recall_score(y_test, y_pred):.4f}")

        st.markdown("---")
        c1, c2 = st.columns(2)

        with c1:
            st.subheader("Matrice de confusion")
            fig, ax = plt.subplots(figsize=(6, 5))
            cm = confusion_matrix(y_test, y_pred)
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                        xticklabels=['Normale', 'Fraude'],
                        yticklabels=['Normale', 'Fraude'],
                        linewidths=1, annot_kws={'size': 16, 'weight': 'bold'})
            ax.set_xlabel("PrÃ©dit", fontweight='bold')
            ax.set_ylabel("RÃ©el",   fontweight='bold')
            ax.set_title("Matrice de Confusion", fontweight='bold')
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
            vp, fn, fp = cm[1,1], cm[1,0], cm[0,1]
            st.markdown(f"- âœ… Fraudes correctement dÃ©tectÃ©es : **{vp}**")
            st.markdown(f"- âŒ Fraudes manquÃ©es (Faux NÃ©gatifs) : **{fn}** âš ï¸")
            st.markdown(f"- âš ï¸ Fausses alarmes (Faux Positifs) : **{fp}**")

        with c2:
            st.subheader("Courbe ROC")
            fpr, tpr, _ = roc_curve(y_test, y_proba)
            fig, ax = plt.subplots(figsize=(6, 5))
            ax.plot(fpr, tpr, color='#e74c3c', lw=2.5,
                    label=f'Random Forest (AUC={auc(fpr,tpr):.4f})')
            ax.plot([0,1],[0,1], 'k--', lw=1.5, label='AlÃ©atoire')
            ax.fill_between(fpr, tpr, alpha=0.15, color='#e74c3c')
            ax.set_xlabel("FPR")
            ax.set_ylabel("TPR")
            ax.set_title("Courbe ROC", fontweight='bold')
            ax.legend(loc='lower right')
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with st.expander("ğŸ“‹ Rapport de classification complet"):
            st.code(classification_report(
                y_test, y_pred, target_names=['Normale', 'Fraude']
            ), language='text')

    except Exception as e:
        st.error(f"âŒ Erreur : {e}")

# ============================================================
# PAGE â€” PRÃ‰DICTION PAR FICHIER (UNIVERSELLE)
# ============================================================
elif page == "ğŸ“‚ PrÃ©diction par fichier":
    st.header("PrÃ©diction en masse â€” Import CSV universel")

    if model is None:
        st.error("âŒ ModÃ¨le non disponible.")
        st.stop()

    st.info("""
    ğŸ“ **Import universel** : importez n'importe quel fichier CSV.
    L'application dÃ©tecte automatiquement les colonnes et s'adapte.
    """)

    uploaded = st.file_uploader("Choisissez un fichier CSV", type=['csv'])

    if uploaded:
        # â”€â”€ Lecture universelle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            try:
                df_up = pd.read_csv(uploaded, sep=None, engine='python')
            except Exception:
                uploaded.seek(0)
                df_up = pd.read_csv(uploaded)

            st.success(f"âœ… Fichier lu : **{len(df_up):,} lignes** â€” **{df_up.shape[1]} colonnes**")
            st.dataframe(df_up.head(5), use_container_width=True)
            st.markdown(f"**Colonnes dÃ©tectÃ©es :** `{'` | `'.join(df_up.columns.tolist())}`")
            st.markdown("---")

        except Exception as e:
            st.error(f"âŒ Impossible de lire le fichier : {e}")
            st.info("VÃ©rifiez que le fichier est bien au format CSV (sÃ©parateur , ou ;).")
            st.stop()

        # â”€â”€ DÃ©tection automatique du mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        cols_model   = feature_cols if feature_cols else []
        cols_present = [c for c in cols_model if c in df_up.columns]
        cols_missing = [c for c in cols_model if c not in df_up.columns]

        if cols_model and len(cols_missing) == 0:
            st.success("âœ… Toutes les colonnes du modÃ¨le sont prÃ©sentes â€” prÃ©diction automatique !")
            mode = "direct"

        elif cols_model and len(cols_present) > 0:
            st.warning(f"âš ï¸ Colonnes manquantes : `{'`, `'.join(cols_missing)}` â†’ remplacÃ©es par 0")
            mode = "partiel"

        else:
            st.info("â„¹ï¸ Les colonnes ne correspondent pas directement â€” associez-les manuellement ci-dessous.")
            mode = "manuel"

        # â”€â”€ Mapping manuel si nÃ©cessaire â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        col_mapping = {}
        if mode == "manuel" and cols_model:
            st.subheader("ğŸ”§ Association des colonnes")
            st.write("Choisissez quelle colonne de votre fichier correspond Ã  chaque variable du modÃ¨le :")
            num_up  = ["-- Ignorer (mettre 0) --"] + \
                      df_up.select_dtypes(include=[np.number]).columns.tolist()
            grid = st.columns(3)
            for i, feat in enumerate(cols_model):
                with grid[i % 3]:
                    sel = st.selectbox(f"{feat}", num_up, key=f"map_{feat}")
                    col_mapping[feat] = sel

        # â”€â”€ Bouton prÃ©diction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.button("ğŸ”® Lancer les prÃ©dictions", type="primary", use_container_width=True):
            try:
                # Construction X selon le mode
                if mode == "direct":
                    X_up = df_up[cols_model].copy()

                elif mode == "partiel":
                    X_up = pd.DataFrame(0.0, index=df_up.index, columns=cols_model)
                    for c in cols_present:
                        X_up[c] = pd.to_numeric(df_up[c], errors='coerce').fillna(0).values

                elif mode == "manuel" and cols_model:
                    X_up = pd.DataFrame(0.0, index=df_up.index, columns=cols_model)
                    for feat, src in col_mapping.items():
                        if src != "-- Ignorer (mettre 0) --" and src in df_up.columns:
                            X_up[feat] = pd.to_numeric(df_up[src], errors='coerce').fillna(0).values

                else:
                    # Aucune info de colonnes â†’ utiliser toutes les numÃ©riques
                    num_df = df_up.select_dtypes(include=[np.number])
                    X_up   = num_df.fillna(0)
                    st.warning("Aucune information de colonnes â€” utilisation de toutes les variables numÃ©riques.")

                # Normalisation
                if scaler_amount is not None and 'Amount' in X_up.columns:
                    X_up['Amount'] = scaler_amount.transform(X_up[['Amount']])
                if scaler_time is not None and 'Time' in X_up.columns:
                    X_up['Time'] = scaler_time.transform(X_up[['Time']])

                X_up = X_up.fillna(0)

                # PrÃ©diction
                preds  = model.predict(X_up)
                probas = model.predict_proba(X_up)[:, 1]

                # RÃ©sultats
                df_res = df_up.copy()
                df_res['PrÃ©diction']          = preds
                df_res['ProbabilitÃ©_Fraude']  = probas.round(4)
                df_res['Statut']              = np.where(preds == 1, 'ğŸ”´ Fraude', 'âœ… Normale')

                n_fraud = int(preds.sum())
                c1, c2, c3 = st.columns(3)
                c1.metric("Total analysÃ©",         f"{len(preds):,}")
                c2.metric("Fraudes dÃ©tectÃ©es",      f"{n_fraud}",
                           delta=f"{n_fraud/len(preds)*100:.2f}%")
                c3.metric("Transactions normales",  f"{len(preds)-n_fraud}")

                # Graphique
                fig, ax = plt.subplots(figsize=(6, 3))
                ax.bar(['Normales', 'Fraudes'],
                       [len(preds)-n_fraud, n_fraud],
                       color=['#2ecc71', '#e74c3c'], edgecolor='black')
                ax.set_title("RÃ©sultats des prÃ©dictions", fontweight='bold')
                ax.set_ylabel("Nombre de transactions")
                for i, v in enumerate([len(preds)-n_fraud, n_fraud]):
                    ax.text(i, v + 0.5, str(v), ha='center', fontweight='bold')
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

                st.subheader("ğŸ“‹ DÃ©tail des prÃ©dictions (50 premiÃ¨res lignes)")
                st.dataframe(
                    df_res[['Statut', 'ProbabilitÃ©_Fraude']].head(50),
                    use_container_width=True
                )

                # TÃ©lÃ©chargement
                csv_out = df_res.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "â¬‡ï¸ TÃ©lÃ©charger tous les rÃ©sultats (CSV)",
                    csv_out,
                    file_name="resultats_predictions.csv",
                    mime="text/csv",
                    type="primary"
                )

            except Exception as e:
                st.error(f"âŒ Erreur lors de la prÃ©diction : {e}")
                st.info("Assurez-vous que les colonnes sÃ©lectionnÃ©es contiennent des valeurs numÃ©riques.")
    else:
        st.markdown("""
        #### ğŸ’¡ Ce que vous pouvez importer :
        - N'importe quel fichier **CSV** (sÃ©parateur virgule ou point-virgule)
        - **Peu importe le nom du fichier**
        - **Peu importe les noms des colonnes** â€” l'application s'adapte :
            - âœ… Colonnes identiques au modÃ¨le â†’ prÃ©diction directe
            - âš ï¸ Colonnes partielles â†’ les manquantes sont mises Ã  0
            - ğŸ”§ Colonnes diffÃ©rentes â†’ vous associez manuellement
        """)

# ============================================================
# PAGE â€” Ã€ PROPOS
# ============================================================
elif page == "â„¹ï¸ Ã€ propos":
    st.header("Ã€ propos de ce projet")
    st.markdown("""
    ### ğŸ“ Partie 3 â€” TP2 IIA | LICENCE MTQ S6 | IUSJ Cameroun 2025-2026
    Par **StÃ©phane C. K. TÃ‰KOUABOU** (PhD & Ing.)

    #### ğŸ› ï¸ Technologies :
    - **Python**, **Scikit-learn**, **Pandas & NumPy**
    - **Matplotlib & Seaborn**, **Streamlit**, **Pickle**

    #### ğŸ¤– ModÃ¨le : Random Forest Classifier
    - OptimisÃ© par **GridSearchCV** (validation croisÃ©e 5 folds)
    - Gestion du dÃ©sÃ©quilibre par **Oversampling**

    | MÃ©trique  | Valeur |
    |-----------|--------|
    | F1-Score  | ~0.95+ |
    | AUC-ROC   | ~0.99+ |
    | Rappel    | ~0.95+ |
    | PrÃ©cision | ~0.95+ |
    """)
    if df is not None:
        st.markdown("---")
        c1, c2, c3 = st.columns(3)
        c1.metric("Transactions", f"{len(df):,}")
        if 'Class' in df.columns:
            c2.metric("Fraudes", f"{df['Class'].sum()}")
        c3.metric("Variables", f"{df.shape[1]}")
    st.success("âœ… Application dÃ©veloppÃ©e avec â¤ï¸ pour l'apprentissage du ML")

# ============================================================
# FOOTER
# ============================================================
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:gray; font-size:14px;'>"
    "ğŸ” Fraud Detector â€” TP2 IIA 2025-2026 | IUSJ Cameroun | "
    "DÃ©veloppÃ© avec Streamlit & Scikit-learn"
    "</div>",
    unsafe_allow_html=True
)
